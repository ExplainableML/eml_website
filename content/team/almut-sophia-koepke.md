---
img: "/team/almutsophia.png"
name: Almut Sophia Koepke
role: Postdoctoral Researcher
order: 2
link: almut-sophia-koepke
mail: a.sophia-koepke (at) uni-tuebingen.de
scholar: https://scholar.google.com/citations?user=q9zQhj8AAAAJ&hl=en
---

# Profile
Almut Sophia Koepke is a post-doctoral researcher in the EML group where she works with [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata). Prior to that, she completed her DPhil in the [Visual Geometry Group (VGG)](https://www.robots.ox.ac.uk/~vgg/) at the University of Oxford, supervised by [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/).

During her PhD, her research focussed on self-supervised learning and on audio-visual learning problems.

# Publications

* Audio-visual generalised zero-shot learning with cross-modal attention and language
[Otniel-Bogdan Mercea](https://www.eml-unitue.de/people/otniel-mercea), Lukas Riesch, A. Sophia Koepke, [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022\
[Paper](https://arxiv.org/pdf/2203.03598.pdf)

&nbsp;

* Audio retrieval with natural language queries: A benchmark study
A. Sophia Koepke\*, [Andreea-Maria Oncescu](https://www.robots.ox.ac.uk/~oncescu/)\*, [Joao F. Henriques](https://www.robots.ox.ac.uk/~joao/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata), [Samuel Albanie](https://samuelalbanie.com/)\
Transactions on Multimedia, 2022\
[Paper](https://arxiv.org/pdf/2112.09418.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/) | [Code](https://github.com/akoepke/audio-retrieval-benchmark)\
<span style="color:blue; font-style:italic">Extension of the INTERSPEECH paper with a new dataset.</span>

&nbsp;

* Audio retrieval with natural language queries
[Andreea-Maria Oncescu](https://www.robots.ox.ac.uk/~oncescu/)\*, A. Sophia Koepke\*, [Joao F. Henriques](https://www.robots.ox.ac.uk/~joao/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata), [Samuel Albanie](https://samuelalbanie.com/)\
INTERSPEECH, 2021\
[Paper](https://arxiv.org/pdf/2105.02192.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/) | [Code](https://github.com/oncescuandreea/audio-retrieval)\
<span style="color:blue; font-style:italic">Shortlisted for best student paper award.</span>

&nbsp;

* Distilling audio-visual knowledge by compositional contrastive learning
[Yanbei Chen](https://www.eml-unitue.de/people/yanbei-chen), [Yongqin Xian](https://www.eml-unitue.de/people/yongqin-xian), A. Sophia Koepke, Ying Shan, [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021\
[Paper](https://arxiv.org/abs/2104.10955) | [Code](https://github.com/yanbeic/CCL)

&nbsp;

* Sight to sound: An end-to-end approach for visual piano transcription
A. Sophia Koepke, [Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), [Yael Moses](https://faculty.idc.ac.il/moses/), [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
The International Conference on Acoustics, Speech, & Signal Processing (ICASSP), 2020\
[Paper](https://www.robots.ox.ac.uk/~vgg/publications/2020/Koepke20/koepke20.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/sighttosound/)\
<span style="color:blue; font-style:italic">Oral presentation.</span>

&nbsp;

* Self-supervised learning of class embeddings from video
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), A. Sophia Koepke, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
IEEE/CVF International Conference on Computer Vision Workshop (ICCV Workshop), 2019\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2019/Wiles19/wiles19.pdf)

&nbsp;

* Visual pitch estimation
A. Sophia Koepke, [Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
Sound and Music Compution Conference (SMC), 2019\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2019/Koepke19/koepke19.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/sighttosound/violinpitch.html)

&nbsp;

* Self-supervised learning of a facial attribute embedding from video
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/)\*, A. Sophia Koepke\*, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
British Machine Vision Conference (BMVC), 2018\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2018/Wiles18a/wiles18a.pdf) | [Supplementary material](http://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/resources/wiles18a_supp.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/fabnet.html) | [Code](https://github.com/oawiles/FAb-Net)\
<span style="color:blue; font-style:italic">Oral presentation.</span>

&nbsp;

* X2Face: A network for controlling face generation by using images, audio, and pose codes
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/)\*, A. Sophia Koepke\*, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
European Conference on Computer Vision (ECCV), 2018\
[Paper](https://www.robots.ox.ac.uk/~vgg/publications/2018/Wiles18/wiles18.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/x2face.html) | [Code](https://github.com/oawiles/X2Face)

&nbsp;

\* denotes equal contribution
