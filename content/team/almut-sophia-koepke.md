---
img: "/team/almutsophia.png"
name: Almut Sophia Koepke
role: Research Fellow
order: 2
link: almut-sophia-koepke
mail: a-sophia.koepke (at) uni-tuebingen.de
scholar: https://scholar.google.com/citations?user=q9zQhj8AAAAJ&hl=en
---

# Profile
Almut Sophia Koepke is a post-doctoral research fellow in the EML group where she works with [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata). Prior to that, she completed her DPhil in the [Visual Geometry Group (VGG)](https://www.robots.ox.ac.uk/~vgg/) at the University of Oxford, supervised by [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/).

Her research focusses on multi-modal learning problems with sound, vision, and language.

# Publications

Waffling around for performance: Visual classification with random words and broad concepts\
[Karsten Roth](https://karroth.com/), [Jae Myung Kim](https://jaemyung-kim.github.io/)\, A. Sophia Koepke, [Oriol Vinyals](https://research.google/people/OriolVinyals/), [Cordelia Schmid](https://thoth.inrialpes.fr/~schmid/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF International Conference on Computer Vision (ICCV), 2023\
[Paper](https://arxiv.org/pdf/2306.07282.pdf) | [Code](https://github.com/ExplainableML/WaffleCLIP)

&nbsp;

Image-free classifier injection for zero-shot classification\
[Anders Christensen](https://www.eml-unitue.de/people/anders-christensen), [Massimiliano Mancini](https://mancinimassimiliano.github.io/), A. Sophia Koepke, [Ole Winther](https://olewinther.github.io/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF International Conference on Computer Vision (ICCV), 2023\
[Paper](#) | [Code](#)

&nbsp;

Zero-shot translation of attention patterns in VQA models to natural language\
[Leonard Salewski](https://www.eml-unitue.de/people/leonard-salewski), A. Sophia Koepke, [Hendrik Lensch](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/mitarbeiter/prof-dr-ing-hendrik-lensch/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
DAGM German Conference on Pattern Recognition (GCPR), 2023\
[Paper](#) | [Code](#)

&nbsp;

Exposing and mitigating spurious correlations for cross-modal retrieval\
[Jae Myung Kim](https://jaemyung-kim.github.io/)\, A. Sophia Koepke, [Cordelia Schmid](https://thoth.inrialpes.fr/~schmid/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
Multimodal Learning and Applications Workshop at the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPRW), 2023\
[Paper](https://arxiv.org/pdf/2304.03391.pdf) | [Code](https://github.com/ExplainableML/Spurious_CM_Retrieval)

&nbsp;

Temporal and cross-modal attention for audio-visual zero-shot learning\
[Otniel-Bogdan Mercea](https://www.eml-unitue.de/people/otniel-mercea)\*, [Thomas Hummel](https://www.eml-unitue.de/people/thomas-hummel)\*, A. Sophia Koepke, [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
European Conference on Computer Vision (ECCV), 2022\
[Paper](https://arxiv.org/pdf/2207.09966.pdf) | [Code](https://github.com/ExplainableML/TCAF-GZSL)

&nbsp;

Audio-visual generalised zero-shot learning with cross-modal attention and language\
[Otniel-Bogdan Mercea](https://www.eml-unitue.de/people/otniel-mercea), Lukas Riesch, A. Sophia Koepke, [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022\
[Paper](https://arxiv.org/pdf/2203.03598.pdf) | [Code](https://github.com/ExplainableML/AVCA-GZSL)

&nbsp;

CLEVR-X: A visual reasoning dataset for natural language explanations\
[Leonard Salewski](https://www.eml-unitue.de/people/leonard-salewski), A. Sophia Koepke, [Hendrik Lensch](https://uni-tuebingen.de/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/mitarbeiter/prof-dr-ing-hendrik-lensch/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
Springer Lecture Notes on Artificial Intelligence, 2022\
[Paper](https://arxiv.org/pdf/2204.02380.pdf) | [Project page](https://explainableml.github.io/CLEVR-X/) | [Code](https://github.com/ExplainableML/CLEVR-X)\
<span style="color:black; font-style:italic">This was also presented at the CVPR 2022 Workshop on Explainable AI for Computer Vision (XAI4CV).</span>

&nbsp;

Audio retrieval with natural language queries: A benchmark study\
A. Sophia Koepke\*, [Andreea-Maria Oncescu](https://www.robots.ox.ac.uk/~oncescu/)\*, [Joao F. Henriques](https://www.robots.ox.ac.uk/~joao/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata), [Samuel Albanie](https://samuelalbanie.com/)\
Transactions on Multimedia, 2022\
[Paper](https://arxiv.org/pdf/2112.09418.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/) | [Code](https://github.com/akoepke/audio-retrieval-benchmark)\
<span style="color:blue; font-style:italic">Extension of the INTERSPEECH paper with a new dataset and new results.</span>

&nbsp;

Audio retrieval with natural language queries\
[Andreea-Maria Oncescu](https://www.robots.ox.ac.uk/~oncescu/)\*, A. Sophia Koepke\*, [Joao F. Henriques](https://www.robots.ox.ac.uk/~joao/), [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata), [Samuel Albanie](https://samuelalbanie.com/)\
INTERSPEECH, 2021\
[Paper](https://arxiv.org/pdf/2105.02192.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/audio-retrieval/) | [Code](https://github.com/oncescuandreea/audio-retrieval)\
<span style="color:blue; font-style:italic">Shortlisted for best student paper award.</span>

&nbsp;

Distilling audio-visual knowledge by compositional contrastive learning\
[Yanbei Chen](https://www.eml-unitue.de/people/yanbei-chen), [Yongqin Xian](https://www.eml-unitue.de/people/yongqin-xian), A. Sophia Koepke, Ying Shan, [Zeynep Akata](https://www.eml-unitue.de/people/zeynep-akata)\
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2021\
[Paper](https://arxiv.org/abs/2104.10955) | [Code](https://github.com/yanbeic/CCL)

&nbsp;

Sight to sound: An end-to-end approach for visual piano transcription\
A. Sophia Koepke, [Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), [Yael Moses](https://faculty.idc.ac.il/moses/), [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
The International Conference on Acoustics, Speech, & Signal Processing (ICASSP), 2020\
[Paper](https://www.robots.ox.ac.uk/~vgg/publications/2020/Koepke20/koepke20.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/sighttosound/)\
<span style="color:blue; font-style:italic">Oral presentation.</span>

&nbsp;

Self-supervised learning of class embeddings from video\
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), A. Sophia Koepke, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
IEEE/CVF International Conference on Computer Vision Workshop (ICCV Workshop), 2019\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2019/Wiles19/wiles19.pdf)

&nbsp;

Visual pitch estimation\
A. Sophia Koepke, [Olivia Wiles](https://www.robots.ox.ac.uk/~ow/), [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
Sound and Music Computation Conference (SMC), 2019\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2019/Koepke19/koepke19.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/sighttosound/violinpitch.html)

&nbsp;

Self-supervised learning of a facial attribute embedding from video\
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/)\*, A. Sophia Koepke\*, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
British Machine Vision Conference (BMVC), 2018\
[Paper](http://www.robots.ox.ac.uk/~vgg/publications/2018/Wiles18a/wiles18a.pdf) | [Supplementary material](http://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/resources/wiles18a_supp.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/fabnet.html) | [Code](https://github.com/oawiles/FAb-Net)\
<span style="color:blue; font-style:italic">Oral presentation.</span>

&nbsp;

X2Face: A network for controlling face generation by using images, audio, and pose codes\
[Olivia Wiles](https://www.robots.ox.ac.uk/~ow/)\*, A. Sophia Koepke\*, [Andrew Zisserman](https://www.robots.ox.ac.uk/~az/)\
European Conference on Computer Vision (ECCV), 2018\
[Paper](https://www.robots.ox.ac.uk/~vgg/publications/2018/Wiles18/wiles18.pdf) | [Project page](https://www.robots.ox.ac.uk/~vgg/research/unsup_learn_watch_faces/x2face.html) | [Code](https://github.com/oawiles/X2Face)

&nbsp;

\* denotes equal contribution

