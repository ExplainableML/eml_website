---
title: MLLM Bias Benchmark Comparison
description: Recently, several benchmarks and datasets have been introduced to measure social biases, particularly gender and racial bias, in multimodal large language models (MLLMs). However, there is still a lack of clear comparisons in terms of quality, coverage, and the insights these benchmarks provide. This project aims to offer a systematic comparison of existing benchmarks using a unified set of state-of-the-art MLLMs, highlighting their strengths, weaknesses, and key differences. If you're interested in this topic, please contact Leander Girrbach (leander.girrbach (at) helmholtz-munich.de).
contactname: Leander Girrbach
contactlink: /people/leander-girrbach